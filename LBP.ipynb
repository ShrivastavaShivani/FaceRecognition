{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pgYAOFGknm_x",
    "outputId": "443bf100-3284-4702-9198-c562de23f6b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QvQtB_vNqwEo"
   },
   "source": [
    "Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0M9Yc7O4EDIs"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing \n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fw3Xlz6tqztd"
   },
   "source": [
    "Loading dataset paths for fetching images from drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPSzDPL8EIhW"
   },
   "outputs": [],
   "source": [
    "files = glob.glob(\"/content/gdrive/My Drive/VR/Project - Face recognition/AVR_data/**/*.jpg\")\n",
    "paths = []\n",
    "names = []\n",
    " \n",
    "for file in files:\n",
    "  #Splitting path name for getting labels\n",
    "  label_str = file.split(\"/\")[-2]\n",
    "  paths.append(file)\n",
    "  names.append(label_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qfBhWBsIq-UK"
   },
   "source": [
    "Function for data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdY46-lRE1I1"
   },
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "  #converting images to grayscale\n",
    "  gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "  #resizing image to 400x400\n",
    "  standard_im = cv2.resize(gray, (400, 400))\n",
    "  return standard_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_l1Y5WVArBWW"
   },
   "source": [
    "Label Encoding of English names into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE95_iS3cQuY"
   },
   "outputs": [],
   "source": [
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder() \n",
    "  \n",
    "# Encode labels in column 'species'. \n",
    "names= label_encoder.fit_transform(names) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JMHt7Dp2rWQV"
   },
   "source": [
    "Loading images from paths and passing them into preprocessing function defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zmurQJCFNp4"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for path in paths:\n",
    "  #Reading image through imread function\n",
    "  img = cv2.imread(path)\n",
    "  #Preprocessing image\n",
    "  pre = preprocess(img)\n",
    "  data.append(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z0dxo1lprkkd"
   },
   "source": [
    "Function for cropping face region out of the image and using it for further processing for face recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iNspSZeRpMNj"
   },
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "  face = []\n",
    "  rect = []\n",
    "\n",
    "  for img in data:\n",
    "    #load OpenCV face detector, I am using LBP which is fast\n",
    "    #there is also a more accurate but slow: Haar classifier\n",
    "    face_cascade = cv2.CascadeClassifier('/content/gdrive/My Drive/VR/Project - Face recognition/haarcascade_frontalface_default.xml')\n",
    "  \n",
    "    #let's detect multiscale images(some images may be closer to camera than others)\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(img, scaleFactor=1.3, minNeighbors=5)\n",
    "  \n",
    "    #if no faces are detected then return original img\n",
    "    if(len(faces) == 0):\n",
    "      face.append(None)\n",
    "      rect.append(None)\n",
    "  \n",
    "    else:\n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "      (x, y, w, h) = faces[0] \n",
    "  \n",
    "    #return only the face part of the image\n",
    "      face.append(img[y:y+w, x:x+h]) \n",
    "      rect.append(faces[0])\n",
    "  return face,rect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Tyo5b2YsLOI"
   },
   "source": [
    "Function to eleminate those images where no face was found by cascade classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi-P0zNoz5N"
   },
   "outputs": [],
   "source": [
    "def only_not_none(face,label,rect):\n",
    "  face_list = []\n",
    "  labels = []\n",
    "  rect_list = []\n",
    "  for face,label,rect in zip(face,names,rect):\n",
    "    if face is not None:\n",
    "      #add face to list of faces\n",
    "      face_list.append(face)\n",
    "      #add label for this face\n",
    "      labels.append(label)\n",
    "      #add rectangle co-ordinates of the face\n",
    "      rect_list.append(rect)\n",
    "  return face_list, labels, rect_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LUX9OKso4rMn"
   },
   "outputs": [],
   "source": [
    "face_data, rect_data = clean(data)\n",
    "face_data,label_data,rect_data = only_not_none(face_data,names,rect_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFVMxvMUrhwd"
   },
   "source": [
    "Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uMyhCRrH7HVB"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(face_data, np.array(label_data), test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oONwwcM_sdZk"
   },
   "source": [
    "Creating LBP Face recognizer model, training model and predicting values of the face labels and finally determining the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Q_qHpCyOwio-",
    "outputId": "fc4ff33f-5d5f-4be8-cf96-04f83166a643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:0.87\n"
     ]
    }
   ],
   "source": [
    "#create our LBPH face recognizer \n",
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "\n",
    "#converting labels into numpy array\n",
    "# nplabels = np.asarray(train_label)\n",
    "# npface_list = np.asarray(train_face)\n",
    "\n",
    "#training LBP model with training data\n",
    "face_recognizer.train(X_train, y_train)\n",
    "\n",
    "# Defining predict function\n",
    "def predict_fun(test_data):\n",
    "  pred = []\n",
    "  for face in test_data:  \n",
    "    #predict the image using our face recognizer \n",
    "    label = face_recognizer.predict(face)\n",
    "\n",
    "    #storing label into list\n",
    "    pred.append(label)\n",
    "  return pred\n",
    "\n",
    "#using predict function to predict labels\n",
    "y_pred = predict_fun(X_test)\n",
    "\n",
    "# Output of predict function gives labels and confidence. Hence, separating labels from confidence\n",
    "pred_label = []\n",
    "for i in y_pred:\n",
    "  pred_label.append(int(i[0]))\n",
    "\n",
    "#storing predicted labels into separate array and converting into int values\n",
    "# final_y = []\n",
    "# for i in pred_label:\n",
    "#   final_y.append(int(i))\n",
    "\n",
    "#Printing final accuracy\n",
    "print(\"accuracy score:{:.2f}\".format(metrics.accuracy_score(y_test, pred_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 742
    },
    "colab_type": "code",
    "id": "NfAQeC3TysTp",
    "outputId": "4acfd56a-d1c9-4def-a23d-d5bfe3c69b97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      0.75      0.86         4\n",
      "           3       1.00      0.67      0.80         3\n",
      "           4       1.00      1.00      1.00         3\n",
      "           5       1.00      1.00      1.00         1\n",
      "           7       1.00      0.50      0.67         2\n",
      "           8       0.75      0.75      0.75         4\n",
      "           9       1.00      1.00      1.00         1\n",
      "          10       1.00      1.00      1.00         4\n",
      "          11       1.00      0.33      0.50         3\n",
      "          12       0.50      1.00      0.67         1\n",
      "          13       1.00      1.00      1.00         3\n",
      "          14       1.00      1.00      1.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.60      1.00      0.75         3\n",
      "          17       1.00      1.00      1.00         3\n",
      "          18       1.00      1.00      1.00         5\n",
      "          19       0.67      1.00      0.80         4\n",
      "          20       1.00      0.67      0.80         3\n",
      "          22       1.00      0.67      0.80         3\n",
      "          23       1.00      0.67      0.80         3\n",
      "          24       1.00      1.00      1.00         5\n",
      "          25       1.00      1.00      1.00         3\n",
      "          27       1.00      1.00      1.00         4\n",
      "          28       1.00      1.00      1.00         3\n",
      "          29       0.57      0.67      0.62         6\n",
      "          30       0.33      1.00      0.50         1\n",
      "          32       1.00      1.00      1.00         1\n",
      "          33       0.75      1.00      0.86         6\n",
      "          34       1.00      1.00      1.00         6\n",
      "          35       1.00      1.00      1.00         1\n",
      "          36       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           0.87       102\n",
      "   macro avg       0.88      0.86      0.85       102\n",
      "weighted avg       0.90      0.87      0.87       102\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred_label))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LBP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
